const { handleError } = require('@librechat/api');
const { logger } = require('@librechat/data-schemas');
const {
  EndpointURLs,
  EModelEndpoint,
  Constants,
  isAgentsEndpoint,
  parseCompactConvo,
} = require('librechat-data-provider');
const azureAssistants = require('~/server/services/Endpoints/azureAssistants');
const assistants = require('~/server/services/Endpoints/assistants');
const anthropic = require('~/server/services/Endpoints/anthropic');
const bedrock = require('~/server/services/Endpoints/bedrock');
const openAI = require('~/server/services/Endpoints/openAI');
const agents = require('~/server/services/Endpoints/agents');
const custom = require('~/server/services/Endpoints/custom');
const google = require('~/server/services/Endpoints/google');
const {
  buildOntarioSystemPrompt,
  getOntarioModel,
  getOntarioFileId,
} = require('~/server/services/prompts/ontario');

const buildFunction = {
  [EModelEndpoint.openAI]: openAI.buildOptions,
  [EModelEndpoint.google]: google.buildOptions,
  [EModelEndpoint.custom]: custom.buildOptions,
  [EModelEndpoint.agents]: agents.buildOptions,
  [EModelEndpoint.bedrock]: bedrock.buildOptions,
  [EModelEndpoint.azureOpenAI]: openAI.buildOptions,
  [EModelEndpoint.anthropic]: anthropic.buildOptions,
  [EModelEndpoint.assistants]: assistants.buildOptions,
  [EModelEndpoint.azureAssistants]: azureAssistants.buildOptions,
};

async function buildEndpointOption(req, res, next) {
  const ontarioModel = getOntarioModel();
  req.body.endpoint = EModelEndpoint.openAI;
  req.body.endpointType = EModelEndpoint.openAI;
  req.body.agent_id = Constants.EPHEMERAL_AGENT_ID;
  req.body.model = ontarioModel;
  req.body.promptPrefix = buildOntarioSystemPrompt();
  logger.info('[Ontario] Config', {
    model: ontarioModel,
    fileId: getOntarioFileId(),
    vectorStoreId: process.env.ONTARIO_OPENAI_VECTOR_STORE_ID,
  });

  const { endpoint, endpointType } = req.body;
  if (endpoint !== EModelEndpoint.openAI || endpointType !== EModelEndpoint.openAI) {
    return handleError(res, { text: 'Only Ontario OpenAI endpoint is allowed' });
  }

  let parsedBody;
  try {
    parsedBody = parseCompactConvo({ endpoint, endpointType, conversation: req.body });
  } catch (error) {
    logger.warn(
      `Error parsing conversation for endpoint ${endpoint}${error?.message ? `: ${error.message}` : ''}`,
    );
    return handleError(res, { text: 'Error parsing conversation' });
  }

  const appConfig = req.config;
  if (appConfig.modelSpecs?.list && appConfig.modelSpecs?.enforce) {
    /** @type {{ list: TModelSpec[] }}*/
    const { list } = appConfig.modelSpecs;
    const { spec } = parsedBody;

    if (!spec) {
      return handleError(res, { text: 'No model spec selected' });
    }

    const currentModelSpec = list.find((s) => s.name === spec);
    if (!currentModelSpec) {
      return handleError(res, { text: 'Invalid model spec' });
    }

    if (endpoint !== currentModelSpec.preset.endpoint) {
      return handleError(res, { text: 'Model spec mismatch' });
    }

    try {
      currentModelSpec.preset.spec = spec;
      if (currentModelSpec.iconURL != null && currentModelSpec.iconURL !== '') {
        currentModelSpec.preset.iconURL = currentModelSpec.iconURL;
      }
      parsedBody = parseCompactConvo({
        endpoint,
        endpointType,
        conversation: currentModelSpec.preset,
      });
    } catch (error) {
      logger.error(`Error parsing model spec for endpoint ${endpoint}`, error);
      return handleError(res, { text: 'Error parsing model spec' });
    }
  }

  const vectorStoreId =
    process.env.ONTARIO_OPENAI_VECTOR_STORE_ID || 'vs_693860848bc48191bccb7c1d197f488f';
  const fileSearchTool = [{ type: 'file_search' }];
  const fileSearchResources = {
    file_search: {
      vector_store_ids: [vectorStoreId],
    },
  };

  parsedBody.promptPrefix = buildOntarioSystemPrompt();
  parsedBody.model = ontarioModel;
  parsedBody.model_parameters = Object.assign({}, parsedBody.model_parameters, {
    model: ontarioModel,
    useResponsesApi: true,
    tools: fileSearchTool,
    tool_choice: 'required',
    tool_resources: fileSearchResources,
    modelKwargs: Object.assign({}, parsedBody.model_parameters?.modelKwargs),
  });
  parsedBody.useResponsesApi = true;
  parsedBody.agent_id = Constants.EPHEMERAL_AGENT_ID;

  // Lock down user-provided overrides and unsupported tools/features
  delete parsedBody.tools;
  delete parsedBody.plugins;
  delete parsedBody.functions;
  delete parsedBody.mcpServers;
  delete parsedBody.files;
  delete req.body.files;

  try {
    const isAgents =
      isAgentsEndpoint(endpoint) || req.baseUrl.startsWith(EndpointURLs[EModelEndpoint.agents]);
    const builder = isAgents
      ? (...args) => buildFunction[EModelEndpoint.agents](req, ...args)
      : buildFunction[endpointType ?? endpoint];

    // TODO: use object params
    req.body.endpointOption = await builder(endpoint, parsedBody, endpointType);
    if (!req.body.endpointOption.modelOptions) {
      req.body.endpointOption.modelOptions = {};
    }
    req.body.endpointOption.modelOptions.model = ontarioModel;
    req.body.endpointOption.modelOptions.useResponsesApi = true;
    req.body.endpointOption.modelOptions.tool_choice = 'required';
    req.body.endpointOption.modelOptions.tools = fileSearchTool;
    req.body.endpointOption.modelOptions.tool_resources = fileSearchResources;
    req.body.endpointOption.modelOptions.modelKwargs = Object.assign(
      {},
      req.body.endpointOption.modelOptions?.modelKwargs,
    );
    // User-provided attachments/uploads are not supported in the Ontario-locked experience.
    req.body.endpointOption.attachments = [];

    // eslint-disable-next-line no-console
    console.log(
      '[Ontario] endpointOption',
      JSON.stringify(req.body.endpointOption, null, 2),
    );

    next();
  } catch (error) {
    logger.error(
      `Error building endpoint option for endpoint ${endpoint} with type ${endpointType}`,
      error,
    );
    return handleError(res, { text: 'Error building endpoint option' });
  }
}

module.exports = buildEndpointOption;
